{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/abc/anaconda3/envs/dlrs/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import argparse\n",
    "# from audioop import rms\n",
    "# import logging\n",
    "import os\n",
    "# from re import L\n",
    "import sys\n",
    "# from itertools import product\n",
    "from time import localtime, sleep, strftime, time\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "import setproctitle # to set the name of process\n",
    "import torch\n",
    "import torch.utils\n",
    "import torch.nn as nn\n",
    "# from tensorboardX import SummaryWriter\n",
    "# from torch import multiprocessing as mp # 多线程工作\n",
    "# from dataset import get_data_queue_cf, get_data_queue_cf_nonsparse\n",
    "from dataset import get_data_queue_efficiently, get_data_queue_negsampling_efficiently # original graph\n",
    "# from dataset import get_data_queue_subsampling_efficiently, get_data_queue_subsampling_efficiently_explicit # subsample\n",
    "from models import (GMF, MLP,  NGCF)\n",
    "# from controller import sample_arch_cf, sample_arch_cf_signal, sample_arch_cf_test\n",
    "from train_eval import (evaluate_cf_efficiently_implicit, train_single_cf_efficiently )\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = argparse.ArgumentParser(description=\"Run.\")\n",
    "parser.add_argument('--lr', type=float, default=0.05, help='init learning rate')\n",
    "# parser.add_argument('--arch_lr', type=float, default=0.05, help='learning rate for arch encoding')\n",
    "parser.add_argument('--controller_lr', type=float, default=1e-1, help='learning rate for controller')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5, help='weight decay')\n",
    "# parser.add_argument('--update_freq', type=int, default=1, help='frequency of updating architeture')\n",
    "parser.add_argument('--opt', type=str, default='Adagrad', help='choice of opt')\n",
    "parser.add_argument('--use_gpu', type=int, default=1, help='whether use gpu')\n",
    "parser.add_argument('--minibatch', type=int, default=1, help='whether use minibatch')\n",
    "parser.add_argument('--gpu', type=int, default=0, help='gpu device id')\n",
    "parser.add_argument('--train_epochs', type=int, default=2000, help='num of training epochs')\n",
    "parser.add_argument('--search_epochs', type=int, default=1000, help='num of searching epochs')\n",
    "parser.add_argument('--save', type=str, default='save/', help='experiment name')\n",
    "parser.add_argument('--seed', type=int, default=1, help='random seed')\n",
    "parser.add_argument('--grad_clip', type=float, default=5, help='gradient clipping')\n",
    "parser.add_argument('--train_portion', type=float, default=0.5, help='portion of training data')\n",
    "parser.add_argument('--valid_portion', type=float, default=0.25, help='portion of validation data')\n",
    "parser.add_argument('--dataset', type=str, default='ml-100k', help='dataset')\n",
    "parser.add_argument('--mode', type=str, default='random_single', help='search or single mode')\n",
    "parser.add_argument('--process_name', type=str, default='AutoCF@wenyan', help='process name')\n",
    "parser.add_argument('--embedding_dim', type=int, default=2, help='dimension of embedding')\n",
    "# parser.add_argument('--controller', type=str, default='PURE', help='structure of controller')\n",
    "# parser.add_argument('--controller_batch_size', type=int, default=4, help='batch size for updating controller')\n",
    "# parser.add_argument('--unrolled', action='store_true', default=True, help='use one-step unrolled validation loss')\n",
    "parser.add_argument('--max_batch', type=int, default=65536, help='max batch during training')\n",
    "parser.add_argument('--device', type=int, default=0, help='GPU device')\n",
    "parser.add_argument('--multi', type=int, default=0, help='using multi-training for single architecture')\n",
    "parser.add_argument('--if_valid', type=int, default=1, help='use validation set for tuning single architecture or not')\n",
    "parser.add_argument('--breakpoint', type=str, default='save/log.txt', help='the log file storing existing results')\n",
    "parser.add_argument('--arch_file', type=str, default='src/arch.txt', help='all arches')\n",
    "parser.add_argument('--remaining_arches', type=str, default='src/arch.txt', help='')\n",
    "parser.add_argument('--arch_assign', type=str, default='[0,3]', help='')\n",
    "parser.add_argument('--data_type', type=str, default='implicit', help='explicit or implicit(default)')\n",
    "parser.add_argument('--loss_func', type=str, default='bprloss', help='Implicit loss function')\n",
    "parser.add_argument('--mark', type=str, default='') # \n",
    "parser.add_argument('--batch_size', type=int, default=5000, help='batch size')\n",
    "# parser.add_argument('--file_id', type=int, default=100, help='file id')\n",
    "\n",
    "# parser.add_argument('--use_sample', type=int, default=0, help='whether use data subgraph')\n",
    "# parser.add_argument('--sample_portion', type=float, default=0.20, help='portion of data subgraph')\n",
    "# parser.add_argument('--sample_mode', type=str, default='distribute', help='topk or distribute mode of sampling')\n",
    "\n",
    "args = parser.parse_args([])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000\n",
      "943 1682\n",
      "tensor(indices=tensor([[   0,    0,    0,  ..., 1676, 1677, 1680],\n",
      "                       [   0,    1,    4,  ...,  853,  862,  895]]),\n",
      "       values=tensor([5., 4., 4.,  ..., 3., 1., 3.]),\n",
      "       device='cuda:0', size=(1682, 943), nnz=50000, layout=torch.sparse_coo)\n"
     ]
    }
   ],
   "source": [
    "dim = 2\n",
    "args.dataset = 'ml-100k'\n",
    "data_path = args.dataset + '/'\n",
    "# setting datasets,  default='ml-100k'\n",
    "if args.dataset == 'ml-100k': # default\n",
    "    num_users = 943\n",
    "    num_items = 1682\n",
    "args.num_users = num_users\n",
    "args.num_items = num_items\n",
    "# only implicit data\n",
    "train_queue_pair, valid_queue, test_queue = get_data_queue_negsampling_efficiently(data_path, args)\n",
    "train_queue_pair = [k.cuda() for k in train_queue_pair]\n",
    "train_queue_pair[3] = train_queue_pair[3].to_sparse()\n",
    "train_queue_pair[4] = train_queue_pair[4].to_sparse() # \n",
    "print(train_queue_pair[4])\n",
    "\n",
    "# data for evaluation\n",
    "all_users = torch.tensor(list(range(num_users)), dtype=torch.int64).repeat_interleave(num_items)\n",
    "all_items = torch.tensor(list(range(num_items)), dtype=torch.int64).repeat(num_users)\n",
    "with torch.cuda.device(args.device):\n",
    "    all_users = all_users.cuda()\n",
    "    all_items = all_items.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# norm ngcf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = train_queue_pair[3].to_dense()\n",
    "R.shape # num_users = 943, num_items = 1682\n",
    "zero_num_users = torch.zeros(num_users, num_users, device=args.device)\n",
    "zero_num_items = torch.zeros(num_items, num_items, device=args.device)\n",
    "adj_mat = torch.concat([torch.concat([zero_num_users, R], dim=1),\n",
    "                torch.concat([R.T, zero_num_items], dim=1)], dim=0) # adjacency matrix\n",
    "# A.shape\n",
    "user_freqency = torch.sum(R > 0.0, axis=1) # train\n",
    "# degree_user_array = # freqency\n",
    "item_freqency = torch.sum(R > 0.0, axis=0)\n",
    "# user_freqency.shape, item_freqency.shape\n",
    "freq_tensor = torch.concat([user_freqency, item_freqency], dim=0)\n",
    "degree_diag = torch.diag(freq_tensor) # degree\n",
    "# D.shape \n",
    "degree_diag_calc = torch.diag(freq_tensor**(-1/2)) # D^(-1/2)\n",
    "# torch.sum(degree_diag_calc == torch.inf) 94\n",
    "# degree_diag_calc[torch.where(degree_diag_calc == torch.inf)] == 0.0\n",
    "degree_diag_calc = torch.where(torch.isinf(degree_diag_calc), torch.full_like(degree_diag_calc, 0), degree_diag_calc)\n",
    "\n",
    "laplace_mat = degree_diag_calc @ adj_mat @ degree_diag_calc # L\n",
    "# laplace_mat[:20, :20]\n",
    "# freq_tensor.shape[0], np.count_nonzero(freq_tensor.cpu()), freq_tensor.shape[0] - np.count_nonzero(freq_tensor.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1131, -0.4657,  0.4829,  ..., -0.2209, -0.1275,  0.5211],\n",
       "        [ 0.1473,  0.5953,  1.5309,  ..., -0.2834, -0.2603,  0.0750],\n",
       "        [ 0.1485, -0.3977, -0.4761,  ..., -0.1025, -0.0662,  0.1304],\n",
       "        ...,\n",
       "        [ 0.2413,  0.3738, -0.8026,  ..., -0.0268,  0.0077,  0.0985],\n",
       "        [-0.2896, -1.5091, -1.3163,  ...,  0.1187,  0.1617, -0.0040],\n",
       "        [-0.7377, -0.8497,  0.4920,  ...,  0.0733,  0.0357, -0.0063]],\n",
       "       device='cuda:0', grad_fn=<CatBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args.embedding_dim = 3\n",
    "# should be changed to encoding\n",
    "embedding_ui = torch.randn(args.num_users + args.num_items, args.embedding_dim,device=args.device)# random input \n",
    "eye_ui = torch.eye(num_items + num_users, device=args.device)\n",
    "dl_0 = args.embedding_dim # encoding\n",
    "dl_1 = 6 # first embedding when l =1\n",
    "dl_2 = 10\n",
    "initializer = nn.init.xavier_uniform_\n",
    "_W1_1 = nn.Linear(dl_0, dl_1,  bias=False, device=args.device)\n",
    "_W2_1 = nn.Linear(dl_0, dl_1,  bias=False, device=args.device)\n",
    "_W1_2 = nn.Linear(dl_1, dl_2,  bias=False, device=args.device)\n",
    "_W2_2 = nn.Linear(dl_1, dl_2,  bias=False, device=args.device)\n",
    "# _W1 = nn.Parameter(initializer(torch.empty(dl_1, dl_2)))\n",
    "# _W2 = nn.Linear(num_items + num_users, dl_1, bias=False, device=args.device)\n",
    "\n",
    "sigmoid_func = nn.LeakyReLU(negative_slope=0.2)\n",
    "# inference = sigmoid_func(_W1((laplace_mat + eye_ui) @ embedding_ui)\n",
    "            #   (laplace_mat@embedding_ui)*_W2(embedding_ui))\n",
    "embedding_ui_0 = embedding_ui # (N+M)*embedding\n",
    "embedding_ui_1 = sigmoid_func(_W1_1((laplace_mat + eye_ui) @ embedding_ui_0) + _W2_1((laplace_mat @ embedding_ui_0)*embedding_ui_0))\n",
    "embedding_ui_2 = sigmoid_func(_W1_2((laplace_mat + eye_ui) @ embedding_ui_1) + _W2_2((laplace_mat @ embedding_ui_1)*embedding_ui_1)) # three layers\n",
    "# enbedding\n",
    "embedding_cat = torch.cat([embedding_ui_0, embedding_ui_1, embedding_ui_2], dim=1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embedding_ui_1, embedding_ui_1.shape, embedding_ui_2, embedding_ui_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50000]) torch.Size([50000, 3])\n"
     ]
    }
   ],
   "source": [
    "_UsersEmbedding = nn.Embedding(num_users, args.embedding_dim, device=args.device)\n",
    "print(users_train.shape, _UsersEmbedding(users_train).shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'norm_adj'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2201540/4018181393.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNGCF\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_users\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_items\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membedding_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight_decay\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'norm_adj'"
     ]
    }
   ],
   "source": [
    "model = NGCF(num_users, num_items, args.embedding_dim, args.weight_decay)\n",
    "\n",
    "model = model.cuda()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=args.lr)\n",
    "\n",
    "losses = []\n",
    "performances = []\n",
    "start = time()\n",
    "for train_epoch in range(args.train_epochs):\n",
    "    loss = train_single_cf_efficiently(train_queue_pair, model, optimizer, args)\n",
    "    \n",
    "    losses.append(loss)\n",
    "    if dim == 2: # default 2， 验证集合上的操作\n",
    "        if 'DMF' in args.mode or 'JNCF' in args.mode: \n",
    "            rmse = evaluate_cf_efficiently_implicit(model, test_queue, all_users, all_items, args)\n",
    "        elif args.mode == 'NGCF':\n",
    "            rmse = evaluate_cf_efficiently_implicit(model, test_queue, all_users, all_items, args)\n",
    "        else: # GMF MLP \n",
    "            rmse  = evaluate_cf_efficiently_implicit(model, test_queue, all_users, all_items, args) \n",
    "    performances.append(rmse)\n",
    "    if train_epoch % 100 == 0 or train_epoch == args.train_epochs - 1:\n",
    "        print('train_epoch: %d, loss: %.4f, recall20: %.4f[%.4f]' % (train_epoch, loss, rmse, time()-start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 4, 3])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([1,2,3])\n",
    "b = np.array([3,2,1])\n",
    "a*b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 1.6489e-16,  4.5643e-41],\n",
       "        [-2.9683e-16,  3.0653e-41],\n",
       "        [ 4.4842e-44,  0.0000e+00]], requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.Parameter(torch.Tensor(3,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('dlrs')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "07c3ee1cf017444eea205f4f170733704bc25c32c3d72c6dcf3487470a4a8cad"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
